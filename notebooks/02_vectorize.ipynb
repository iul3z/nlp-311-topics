{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "10382eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl Texte: 364558\n",
      "Beispiel 1: loud music party\n",
      "Beispiel 2: access\n",
      "Beispiel 3: access\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# breinigte Daten aus Schritt 1\n",
    "csv_path = r\"C:\\projct nlp 311\\data\\text_clean.csv\"\n",
    "\n",
    "df_clean = pd.read_csv(csv_path, encoding=\"utf-8\")\n",
    "texts = df_clean[\"text_clean\"].fillna(\"\").astype(str).tolist()\n",
    "\n",
    "# Testausgabe, kurzer Einblick\n",
    "\n",
    "print(\"Anzahl Texte:\", len(texts))\n",
    "print(\"Beispiel 1:\", texts[0] if len(texts) > 0 else \"<leer>\")\n",
    "print(\"Beispiel 2:\", texts[1] if len(texts) > 1 else \"<leer>\")\n",
    "print(\"Beispiel 3:\", texts[2] if len(texts) > 2 else \"<leer>\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2caffb1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF-Form: (364558, 68)\n",
      "Anzahl Terme: 68\n",
      "Beispiel-Terme: ['access', 'area', 'banging', 'blocked', 'blocking', 'building', 'bus', 'car', 'chained', 'chronic', 'commercial', 'complaint', 'congestion', 'detached', 'details']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#Parameter\n",
    "vec = TfidfVectorizer(min_df=5, max_df=0.9, max_features=10000)\n",
    "\n",
    "X_tfidf = vec.fit_transform(texts)   # Matrix Dokumente und Terme\n",
    "terms = vec.get_feature_names_out()\n",
    "\n",
    "# Testausgabe, kurzer Einblick\n",
    "\n",
    "print(\"TF-IDF-Form:\", X_tfidf.shape)       \n",
    "print(\"Anzahl Terme:\", len(terms))\n",
    "print(\"Beispiel-Terme:\", list(terms[:15]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3d218cff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSA-Form: (364558, 10)\n",
      "\n",
      "游릭 Thema 1: access, partial, language, complaint, details, parking, layover, unauthorized\n",
      "\n",
      "游릭 Thema 2: loud, party, music, talking, car, truck, horn, television\n",
      "\n",
      "游릭 Thema 3: parking, posted, sign, violation, overnight, commercial, storage, route\n",
      "\n",
      "游릭 Thema 4: blocked, hydrant, sidewalk, route, parking, unauthorized, layover, bus\n",
      "\n",
      "游릭 Thema 5: plate, license, route, parking, unauthorized, layover, bus, horn\n",
      "\n",
      "游릭 Thema 6: talking, loud, parking, sign, posted, commercial, overnight, television\n",
      "\n",
      "游릭 Thema 7: partial, storage, unlicensed, chained, traffic, sign, posted, area\n",
      "\n",
      "游릭 Thema 8: overnight, commercial, parking, storage, party, loud, television, unlicensed\n",
      "\n",
      "游릭 Thema 9: car, truck, horn, talking, music, overnight, commercial, route\n",
      "\n",
      "游릭 Thema 10: blocking, parked, double, traffic, vehicle, storage, unlicensed, complaint\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "import numpy as np\n",
    "\n",
    "# Reduzieren auf wenige Dimensionen/Themen\n",
    "\n",
    "lsa = TruncatedSVD(n_components=10, random_state=42)\n",
    "X_lsa = lsa.fit_transform(X_tfidf)\n",
    "\n",
    "print(\"LSA-Form:\", X_lsa.shape)\n",
    "\n",
    "# Begriffe mit h칬chstem Gewicht je Thema anzeigen\n",
    "\n",
    "terms = vec.get_feature_names_out()\n",
    "n_top_terms = 8\n",
    "\n",
    "for i, comp in enumerate(lsa.components_):\n",
    "    top_indices = np.argsort(comp)[::-1][:n_top_terms]\n",
    "    top_terms = [terms[j] for j in top_indices]\n",
    "    print(f\"\\n游릭 Thema {i+1}: {', '.join(top_terms)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "11ca2ee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster\n",
      "0    33849\n",
      "1    75888\n",
      "2    69708\n",
      "3    27200\n",
      "4    53633\n",
      "5    23810\n",
      "6    24993\n",
      "7    21661\n",
      "8    17099\n",
      "9    16717\n",
      "Name: count, dtype: int64\n",
      "\n",
      "游댳 Cluster 0: blocked, hydrant, sidewalk, language, est, gridlock, horn, hours, idling, layover\n",
      "\n",
      "游댳 Cluster 1: access, language, est, gridlock, horn, hours, hydrant, idling, layover, vehicle\n",
      "\n",
      "游댳 Cluster 2: party, music, loud, violation, idling, est, gridlock, horn, hours, hydrant\n",
      "\n",
      "游댳 Cluster 3: posted, sign, violation, parking, music, loud, licensed, license, layover, language\n",
      "\n",
      "游댳 Cluster 4: parked, double, blocking, traffic, vehicle, idling, engine, neglected, pounding, banging\n",
      "\n",
      "游댳 Cluster 5: talking, loud, violation, idling, est, gridlock, horn, hours, hydrant, language\n",
      "\n",
      "游댳 Cluster 6: partial, access, language, est, gridlock, horn, hours, hydrant, idling, layover\n",
      "\n",
      "游댳 Cluster 7: plate, license, violation, idling, est, gridlock, horn, hours, hydrant, layover\n",
      "\n",
      "游댳 Cluster 8: overnight, commercial, parking, storage, violation, idling, gridlock, horn, hours, hydrant\n",
      "\n",
      "游댳 Cluster 9: car, truck, music, horn, language, est, gridlock, hours, hydrant, idling\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# K-Means Cluster\n",
    "k = 10 \n",
    "kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "clusters = kmeans.fit_predict(X_lsa)\n",
    "\n",
    "# jedem Text das Cluster zuweisen\n",
    "\n",
    "df_clean[\"cluster\"] = clusters\n",
    "\n",
    "# kurze 칖bersicht\n",
    "\n",
    "print(df_clean[\"cluster\"].value_counts().sort_index())\n",
    "\n",
    "# Begriffe, je Cluster\n",
    "\n",
    "for i in range(k):\n",
    "    cluster_indices = np.where(clusters == i)[0]\n",
    "    cluster_texts = [texts[j] for j in cluster_indices]\n",
    "    joined = \" \".join(cluster_texts)\n",
    "    tfidf_sub = vec.transform([joined])\n",
    "    top_terms = [terms[t] for t in np.argsort(tfidf_sub.toarray()[0])[::-1][:10]]\n",
    "    print(f\"\\n游댳 Cluster {i}: {', '.join(top_terms)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f0480b2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ergebnisse gespeichert unter: ../data/311_clustered_sample.csv\n"
     ]
    }
   ],
   "source": [
    "# Ergebnisse speichern \n",
    "\n",
    "output_path = \"../data/311_clustered_sample.csv\"\n",
    "df_clean[[\"text_clean\", \"cluster\"]].to_csv(output_path, index=False)\n",
    "print(\"Ergebnisse gespeichert unter:\", output_path)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
